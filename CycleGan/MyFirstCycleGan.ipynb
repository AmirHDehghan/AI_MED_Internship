{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MyFirstCycleGan.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM05oMOJCXBDMdJYl9pXfNO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AmirHDehghan/AI_MED_Internship/blob/main/CycleGan/MyFirstCycleGan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJAdH4UqWBJB",
        "outputId": "727b8598-31a9-45fe-9c54-3b244b425df3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable\n",
        "\n",
        "from __future__ import print_function\n",
        "#%matplotlib inline\n",
        "import argparse\n",
        "import os\n",
        "import random\n",
        "import torch.nn.parallel\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as vutils\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "from IPython.display import HTML\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "# Set random seed for reproducibility\n",
        "manualSeed = 999\n",
        "#manualSeed = random.randint(1, 10000) # use if you want new results\n",
        "#print(\"Random Seed: \", manualSeed)\n",
        "random.seed(manualSeed)\n",
        "torch.manual_seed(manualSeed)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fec98e0e570>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOsSLgDsWUcG"
      },
      "source": [
        "# Batch size during training\n",
        "batch_size = 1\n",
        "\n",
        "# Spatial size of training images. All images will be resized to this\n",
        "#   size using a transformer.\n",
        "image_size = 32\n",
        "\n",
        "# Number of channels in the training images. For color images this is 3\n",
        "nc = 1\n",
        "\n",
        "# Size of z latent vector (i.e. size of generator input)\n",
        "nz = 100\n",
        "\n",
        "# Size of feature maps in generator\n",
        "ngf = 64\n",
        "\n",
        "# Size of feature maps in discriminator\n",
        "ndf = 64\n",
        "\n",
        "# Number of training epochs\n",
        "num_epochs = 200\n",
        "\n",
        "# Learning rate for optimizers\n",
        "lr = 0.0002\n",
        "\n",
        "# Beta1 hyperparam for Adam optimizers\n",
        "beta1 = 0.5\n",
        "\n",
        "# Number of GPUs available. Use 0 for CPU mode.\n",
        "ngpu = 1\n",
        "\n",
        "# The point that LR starts to decay\n",
        "decay_epoch = 100\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcH8GU7fWZ6W"
      },
      "source": [
        "train_data = dset.MNIST(root = './data', train = True,\n",
        "                        transform = transforms.Compose([\n",
        "                               transforms.Resize(image_size),\n",
        "                               transforms.CenterCrop(image_size),\n",
        "                               transforms.ToTensor(),\n",
        "                               transforms.Normalize((0.5), (0.5)),\n",
        "                           ]), download = True)\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3MC-DcIWiDV"
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
        "                                         shuffle=True, num_workers=0)\n",
        "\n",
        "# Decide which device we want to run on\n",
        "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRbdWgZzWo3k",
        "outputId": "0c06139d-ce5b-48ad-c8b7-59a66f227a3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499
        }
      },
      "source": [
        "# Plot some training images\n",
        "#transforms.functional.crop(test_loader,0,0,14,14)\n",
        "real_batch = next(iter(train_loader))\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Training Images\")\n",
        "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=2, normalize=True).cpu(),(1,2,0)))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fec4d2aecc0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKkRs8YaWxrI"
      },
      "source": [
        "class Generator(nn.Module):\n",
        "  def __init__(self, ngpu):\n",
        "    super(Generator,self).__init__()\n",
        "    \n",
        "    self.ngpu = ngpu\n",
        "    self.encoder = nn.Sequential(\n",
        "        # nn.ReflectioanPad2d(3),\n",
        "        nn.Conv2d(1, 64, 7, 1, 3),\n",
        "        nn.InstanceNorm2d(64),\n",
        "        nn.ReLU(inplace=True),\n",
        "\n",
        "        # nn.ReflectioanPad2d(1),\n",
        "        nn.Conv2d(64, 128, 3, 2, 1),\n",
        "        nn.InstanceNorm2d(128),\n",
        "        nn.ReLU(inplace=True),\n",
        "\n",
        "        # nn.ReflectioanPad2d(3),\n",
        "        nn.Conv2d(128, 256, 3, 2, 3),\n",
        "        nn.InstanceNorm2d(256),\n",
        "        nn.ReLU(inplace=True)\n",
        "    )\n",
        "\n",
        "    self.transformer = nn.Sequential(\n",
        "        \n",
        "        # nn.ReflectioanPad2d(1),\n",
        "        nn.Conv2d(256, 256, 3, 1, 1),\n",
        "        nn.InstanceNorm2d(256),\n",
        "        nn.ReLU(inplace=True)\n",
        "\n",
        "    )\n",
        "\n",
        "    self.decoder = nn.Sequential(\n",
        "        \n",
        "        # nn.ReflectioanPad2d(1),\n",
        "        nn.ConvTranspose2d(256, 128, 3, 2, 1, output_padding=1),\n",
        "        nn.InstanceNorm2d(128),\n",
        "        nn.ReLU(inplace=True),\n",
        "\n",
        "        # nn.ReflectioanPad2d(1),\n",
        "        nn.ConvTranspose2d(128 , 64, 3, 2, 1, output_padding=1),\n",
        "        nn.InstanceNorm2d(64),\n",
        "        nn.ReLU(inplace=True),\n",
        "\n",
        "        # nn.ReflectioanPad2d(3),\n",
        "        nn.Conv2d(64, 1, 7, 1, 3),\n",
        "        nn.InstanceNorm2d(128),\n",
        "        nn.ReLU(inplace=True)\n",
        "\n",
        "    )\n",
        "\n",
        "  def forward(self, input):\n",
        "    \n",
        "    self.encoded = self.encoder(input)\n",
        "    self.transformed = self.transformer(self.encoded)\n",
        "    \n",
        "    for t in range(5):\n",
        "      self.transformed = self.transformer(self.transformed)\n",
        "    \n",
        "    self.decoded = self.decoder(self.transformed)\n",
        "\n",
        "    return self.decoded"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7h74xKUqxcI"
      },
      "source": [
        "class PatchGanDis(nn.Module):\n",
        "  def __init__(self, ngpu):\n",
        "    super(PatchGanDis,self).__init__()\n",
        "\n",
        "    self.ngpu = ngpu\n",
        "    self.main = nn.Sequential(\n",
        "        \n",
        "        # nn.ReflectionPad2d(1),\n",
        "        nn.Conv2d(1, 64, 4, 2, 1),\n",
        "        nn.InstanceNorm2d(64),\n",
        "        nn.LeakyReLU(0.01, inplace= False),\n",
        "                \n",
        "        # nn.ReflectionPad2d(1),\n",
        "        nn.Conv2d(64, 128, 4, 2, 1),\n",
        "        nn.InstanceNorm2d(128),\n",
        "        nn.LeakyReLU(0.01, inplace= False),\n",
        "                \n",
        "        # nn.ReflectionPad2d(1),\n",
        "        nn.Conv2d(128, 256, 4, 2, 1),\n",
        "        nn.InstanceNorm2d(256),\n",
        "        nn.LeakyReLU(0.01, inplace= False),\n",
        "                \n",
        "        # nn.ReflectionPad2d(1),\n",
        "        nn.Conv2d(256, 512, 4, 2, 1),\n",
        "        nn.InstanceNorm2d(512),\n",
        "        nn.LeakyReLU(0.01, inplace= False),\n",
        "\n",
        "        # nn.ReflectionPad2d(2),\n",
        "        nn.Conv2d(512, 1, 4, 1, 2),\n",
        "        nn.InstanceNorm2d(1),\n",
        "        nn.LeakyReLU(0.01, inplace= False)     \n",
        "    )\n",
        "\n",
        "  def forward(self, input):\n",
        "    print(input.shape)\n",
        "    yy = self.main(input)\n",
        "    print(yy.shape)\n",
        "    return self.main(input)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHU9B_OpzOTt"
      },
      "source": [
        "def weights_init_normal(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        torch.nn.init.normal(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find('BatchNorm2d') != -1:\n",
        "        torch.nn.init.normal(m.weight.data, 1.0, 0.02)\n",
        "        torch.nn.init.constant(m.bias.data, 0.0)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stXCfjVPWx1l",
        "outputId": "b925489c-e618-41e8-fe0b-02e019ef65f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Create the generator\n",
        "netG_a2b = Generator(ngpu).to(device)\n",
        "netG_b2a = Generator(ngpu).to(device)\n",
        "\n",
        "netPGD_a2b = PatchGanDis(ngpu).to(device)\n",
        "# netPGD_b2a = PatchGanDis(ngpu).to(device)\n",
        "\n",
        "# Apply the weights_init function to randomly initialize all weights\n",
        "#  to mean=0, stdev=0.2.\n",
        "netG_a2b.apply(weights_init_normal)\n",
        "netG_b2a.apply(weights_init_normal)\n",
        "netPGD_a2b.apply(weights_init_normal)\n",
        "# netPGD_b2a.apply(weights_init_normal)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    netG_a2b.cuda()\n",
        "    netG_b2a.cuda()\n",
        "    netPGD_a2b.cuda()\n",
        "    # netPGD_b2a.cuda()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpohTqZ4dsSB"
      },
      "source": [
        "class LambdaLR():\n",
        "    def __init__(self, num_epochs, decay_start_epoch):\n",
        "        assert ((num_epochs - decay_start_epoch) > 0), \"Decay must start before the training session ends!\"\n",
        "        self.num_epochs = num_epochs\n",
        "        self.decay_start_epoch = decay_start_epoch\n",
        "\n",
        "    def step(self, training_epoch):  # training_epoch : the right-now iteration number of epoch \n",
        "        return 1.0 - max(0, training_epoch - self.decay_start_epoch)/(self.num_epochs - self.decay_start_epoch)\n"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIKYWtTxW1mr"
      },
      "source": [
        "# Initializing Loss!\n",
        "criterion_GAN = torch.nn.MSELoss()\n",
        "criterion_cycle = torch.nn.L1Loss()\n",
        "# criterion_identity = torch.nn.L1Loss()\n",
        "\n",
        "\n",
        "real_label = torch.ones(2,2)\n",
        "fake_label = torch.zeros(2,2)\n",
        "\n",
        "# Optimizer Initialization\n",
        "OptimizerG_a2b = optim.Adam(netG_a2b.parameters(), lr=lr, betas=(beta1,0.999))\n",
        "OptimizerPGD_a2b = optim.Adam(netPGD_a2b.parameters(), lr=lr, betas=(beta1,0.999))\n",
        "OptimizerG_b2a = optim.Adam(netG_b2a.parameters(), lr=lr, betas=(beta1,0.999))\n",
        "# OptimizerPGD_b2a = optim.Adam(netPGD_b2a.parameters(), lr=lr, betas=(beta1,0.999))\n",
        "\n",
        "\n",
        "\n",
        "lr_scheduler_G_a2b = torch.optim.lr_scheduler.LambdaLR(OptimizerG_a2b, lr_lambda=LambdaLR(num_epochs, decay_epoch).step)\n",
        "lr_schedulerPGD_a2b = torch.optim.lr_scheduler.LambdaLR(OptimizerPGD_a2b, lr_lambda=LambdaLR(num_epochs, decay_epoch).step)\n",
        "lr_schedulerG_b2a = torch.optim.lr_scheduler.LambdaLR(OptimizerG_b2a, lr_lambda=LambdaLR(num_epochs, decay_epoch).step)\n",
        "# lr_schedulerPGD_b2a = torch.optim.lr_scheduler.LambdaLR(OptimizerPGD_b2a, lr_lambda=LambdaLR(num_epochs, decay_epoch).step)\n"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOXpCvvAnsyo",
        "outputId": "77fc099c-70c0-4003-99ef-e1afe7f1480e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# generated_noises = torch.randn(1,1,32,32)\n",
        "# generated_noises.shape"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1, 32, 32])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wS07-L8fW5Kc",
        "outputId": "ec206a4a-1ff0-44d8-b7b1-d90199235a1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        }
      },
      "source": [
        "#Training Phase\n",
        "\n",
        "# Keeping Track...\n",
        "\n",
        "img_list= []\n",
        "Dlosses= []\n",
        "Glosses= []\n",
        "Cycle_losses= []\n",
        "\n",
        "iters= 0\n",
        "\n",
        "# The Loop:\n",
        "for epoch in range(num_epochs):\n",
        "  # Each epoch:\n",
        "  for i, image in enumerate(train_loader,0):\n",
        "\n",
        "    real_cpu = image[0].to(device)\n",
        "    b_size = real_cpu.size(0)\n",
        "    # label = torch.full((b_size,),real_label,dtype=torch.float,device=device)\n",
        "    generated_noise = torch.randn(1,1,32,32)\n",
        "\n",
        "    # PatchGan Discriminator\n",
        "    # Update Real Batch\n",
        "    netPGD_a2b.zero_grad()\n",
        "    output = netPGD_a2b(real_cpu)\n",
        "    rb_Dloss = criterion_GAN(output, real_label)\n",
        "    rb_Dloss.backward()\n",
        "\n",
        "    # Update Fake Batch\n",
        "    fake = netG_a2b(generated_noise)\n",
        "    output = netPGD_a2b(fake.detach())\n",
        "    fb_Dloss = criterion_GAN(output, fake_label)\n",
        "    fb_Dloss.backward()\n",
        "\n",
        "    Dloss = fb_Dloss + rb_Dloss\n",
        "\n",
        "    OptimizerPGD_a2b.step()\n",
        "\n",
        "    # Generating fake image from noise AND computing MSE:\n",
        "    netG_a2b.zero_grad()\n",
        "    # fake_image = netG_a2b(generated_noise)\n",
        "    output = netPGD_a2b(fake)\n",
        "    Gloss = criterion_GAN(output, real_label) \n",
        "    Gloss.backward()\n",
        "\n",
        "    OptimizerG_a2b.step()\n",
        "\n",
        "    # Update b2a\n",
        "    recoverd_noise = netG_b2a(fake)\n",
        "    cycle_loss = criterion_cycle(recoverd_noise, generated_noise)\n",
        "    cycle_loss.backward()\n",
        "\n",
        "    OptimizerG_b2a.step()\n",
        "    #if i % 50 == 0:\n",
        "     #       print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f'\n",
        "      #            % (epoch, num_epochs, i, len(train_loader),\n",
        "       #              errD.item(), errG.item()))\n",
        "    # if (iters % 500 == 0) or ((epoch == num_epochs-1) and (i == len(train_loader)-1)):\n",
        "    #         with torch.no_grad():\n",
        "    #             fake = netG(fixed_noise,real_cpu_half).detach().to(device)\n",
        "    #         img_list.append(vutils.make_grid(torch.cat([fake,real_cpu[:,:,:,32:]],dim=3), padding=2, normalize=True).tolist())\n",
        "    #score = calculate_inception_score(asarray([imagel,fake.tolist()]))\n",
        "    #print(\"score of inception:\",score)\n",
        "    print('[%d/%d][%d/%d]\\tLoss_PGD: %.4f\\tLoss_G_a2a: %.4f\\tCycle_Loss: %.4f'\n",
        "                  % (epoch, num_epochs, i, len(train_loader),\n",
        "                     Dloss.item(), Gloss.item(), cycle_loss.item()))\n",
        "\n",
        "    iters += 1\n",
        "    \n",
        "    \n",
        "    Glosses.append(Gloss.item())\n",
        "    Dlosses.append(Dloss.item())\n",
        "    Cycle_losses.append(cycle_loss.item())   \n",
        "    "
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 1, 32, 32])\n",
            "torch.Size([1, 1, 3, 3])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([2, 2])) that is different to the input size (torch.Size([1, 1, 3, 3])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-4289ec0cb262>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mnetPGD_a2b\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetPGD_a2b\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_cpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mrb_Dloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion_GAN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mrb_Dloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   2645\u001b[0m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreduction\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'mean'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2646\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2647\u001b[0;31m         \u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2648\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2649\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/functional.py\u001b[0m in \u001b[0;36mbroadcast_tensors\u001b[0;34m(*tensors)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhas_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (3) must match the size of tensor b (2) at non-singleton dimension 3"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZUxJxh2W807"
      },
      "source": [
        "#  Plotting the losses\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.title(\"Generator and Discriminator Loss During Training\")\n",
        "plt.plot(G_losses,label=\"G\")\n",
        "plt.plot(D_losses,label=\"D\")\n",
        "plt.xlabel(\"iterations\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hk8ho6NhXAqV"
      },
      "source": [
        "#Visualization of Gâ€™s progression\n",
        "fig = plt.figure(figsize=(8,8))\n",
        "plt.axis(\"off\")\n",
        "ims = [[plt.imshow(np.transpose(i,(1,2,0)), animated=True)] for i in img_list]\n",
        "ani = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)\n",
        "\n",
        "HTML(ani.to_jshtml())"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}